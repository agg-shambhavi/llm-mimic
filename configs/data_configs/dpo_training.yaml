parameters:
  finetuning_type: dpo
  num_train_epochs: 3
  per_device_train_batch_size: 2
  learning_rate: 3e-4
  dataset_huggingface_workspace: agg-shambhavi
  is_dummy: false