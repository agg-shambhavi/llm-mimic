parameters:
  finetuning_type: sft
  num_train_epochs: 3
  per_device_train_batch_size: 1
  learning_rate: 3e-4
  dataset_huggingface_workspace: agg-shambhavi
  is_dummy: true